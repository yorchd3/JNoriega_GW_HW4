{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[The path to the resume information is described so it can be used to get that information after. The sets are created to define the words that are required and the ones that are desired]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Here we create the function load_file and it will help read the file and return its single elements or tokens]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[This cell is passing the resume data from from the file resume.md to the function created above to get the contents of the md file]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* Why is a `set` created?\n",
    "To later add information to the set\n",
    "* How are we populating the set\n",
    "We are populating the set with the tokens in the word list which is the output of passing resume_path to the load_file function\n",
    "* Why would it be necessary to create a `punctuation` set?\n",
    "To later remove punctuation and have a clean set of tokens\n",
    "* What does subtracting from the set do?\n",
    "It removes the punctuation from the set to clean the data\n",
    "* * Refer to the `resume = resume - punctuation` line\n",
    "* What does `\\n` do in a string\n",
    "That adds a blank line before a new line with text starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'##', 'with', 'skills', 'pandas', '#', 'data', 'apis.', 'learning', 'visualizations', 'developing', 'web', 'analytics', 'business', 'git/github', 'd3,', 'learning,', 'interests', 'n.', 'files', 'tableau,', 'apps', 'api', 'excel.', 'aws', 'microsoft', 'r,', 'sql,', 'big', 'sets', 'excel,', 'writing', 'css,', 'using', 'tableau', 'javascript,', 'html,', 'to', 'basic', 'leaflet.js', 'social', 'statistics,', 'machine', 'python', 'algorithms', 'stein', 'mysql', 'forecasting', 'open-source', 'graduate', 'frank', 'education', 'databases', 'experience', 'intelligence', 'from', '*', 'interactions,', 'designing', 'visualization', 'scripts', 'tables', 'hadoop,', 'analyze', 'cloud', 'creating', 'modeling', 'statistics', 'and', 'html/css,', 'mining,', 'camp', 'mongodb', 'in', 'python,', 'pivot', 'boot', 'contributing', 'hadoop', 'software', 'vba', 'bootstrap,', 'media', 'working', 'performing', 'mining', 'd3', 'the', 'advanced', 'front-end'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'##', 'with', 'skills', 'pandas', 'data', 'learning', 'apis.', 'visualizations', 'developing', 'web', 'analytics', 'business', 'git/github', 'd3,', 'learning,', 'interests', 'n.', 'files', 'tableau,', 'apps', 'api', 'excel.', 'aws', 'microsoft', 'r,', 'sql,', 'big', 'sets', 'excel,', 'writing', 'css,', 'using', 'tableau', 'javascript,', 'html,', 'to', 'basic', 'social', 'leaflet.js', 'statistics,', 'machine', 'python', 'algorithms', 'stein', 'mysql', 'forecasting', 'open-source', 'graduate', 'frank', 'education', 'databases', 'experience', 'intelligence', 'from', 'interactions,', 'designing', 'visualization', 'scripts', 'tables', 'hadoop,', 'analyze', 'cloud', 'creating', 'modeling', 'statistics', 'and', 'html/css,', 'mining,', 'camp', 'mongodb', 'in', 'python,', 'pivot', 'boot', 'contributing', 'hadoop', 'software', 'vba', 'bootstrap,', 'media', 'working', 'performing', 'mining', 'd3', 'the', 'advanced', 'front-end'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* What does using a `set` intersection do in this section?\n",
    "Finds common words between sets\n",
    "* How does the character cleaning function work differently than the word cleaning function? (test it)\n",
    "It applies the cleaning letter by letter and not word by word\n",
    "* Can you add more items to the `stop_words` list?\n",
    "Yes because it is a list\n",
    "* Explain how the list `word_list` list comprehension works. What does it return and what is the filtering criteria?\n",
    "It works like a for loop. For each word in the word list checks if the word is in the group of stop words. When it hits the stop word it prints the word after the stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'python', 'statistics', 'mysql'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below.\n",
    "Be sure to explain the following:\n",
    "\n",
    "* How was the `word_count` dictionary initialized, what were in initial key values, and how were they set?\n",
    "It is initialized with default key values as the words in the word list and the values for each key equal to zero\n",
    "* Explain the logic behind incrementing the world count value using the `for loop`. Be sure to explain how to reference the word key in the `word_count` dictionary\n",
    "This for loop is counting the number of times the key word appears and accumulating the count of those key words\n",
    "* Collections.counter is optional, but explain the difference between the `for loop` and using `Counter`\n",
    "This would make it faster to count the number of key words in the word list. At the end it does the same as the for loop but the counter would sort it to output the words with the higher count first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frank': 1, 'n': 1, 'stein': 1, 'education': 1, 'data': 7, 'analytics': 3, 'visualization': 2, 'boot': 1, 'camp': 1, 'graduate': 1, 'experience': 1, 'creating': 1, 'pivot': 1, 'tables': 1, 'vba': 1, 'scripts': 2, 'excel': 2, 'modeling': 1, 'forecasting': 1, 'basic': 1, 'statistics': 2, 'writing': 1, 'python': 4, 'analyze': 1, 'sets': 1, 'from': 1, 'files': 1, 'apis': 1, 'social': 2, 'media': 2, 'mining': 2, 'mysql': 1, 'mongodb': 1, 'databases': 1, 'developing': 1, 'frontend': 1, 'web': 2, 'visualizations': 1, 'html': 2, 'css': 2, 'bootstrap': 1, 'd3': 2, 'leafletjs': 1, 'the': 2, 'tableau': 2, 'business': 1, 'intelligence': 1, 'software': 2, 'performing': 1, 'big': 2, 'hadoop': 2, 'machine': 2, 'learning': 2, 'algorithms': 1, 'skills': 1, 'microsoft': 1, 'javascript': 2, 'htmlcss': 1, 'api': 1, 'interactions': 1, 'sql': 1, 'advanced': 1, 'r': 1, 'gitgithub': 1, 'interests': 1, 'contributing': 1, 'opensource': 1, 'pandas': 1, 'designing': 1, 'apps': 1, 'cloud': 1, 'aws': 1}\n",
      "Counter({'data': 7, 'python': 4, 'analytics': 3, 'visualization': 2, 'scripts': 2, 'excel': 2, 'statistics': 2, 'social': 2, 'media': 2, 'mining': 2, 'web': 2, 'html': 2, 'css': 2, 'd3': 2, 'the': 2, 'tableau': 2, 'software': 2, 'big': 2, 'hadoop': 2, 'machine': 2, 'learning': 2, 'javascript': 2, 'frank': 1, 'n': 1, 'stein': 1, 'education': 1, 'boot': 1, 'camp': 1, 'graduate': 1, 'experience': 1, 'creating': 1, 'pivot': 1, 'tables': 1, 'vba': 1, 'modeling': 1, 'forecasting': 1, 'basic': 1, 'writing': 1, 'analyze': 1, 'sets': 1, 'from': 1, 'files': 1, 'apis': 1, 'mysql': 1, 'mongodb': 1, 'databases': 1, 'developing': 1, 'frontend': 1, 'visualizations': 1, 'bootstrap': 1, 'leafletjs': 1, 'business': 1, 'intelligence': 1, 'performing': 1, 'algorithms': 1, 'skills': 1, 'microsoft': 1, 'htmlcss': 1, 'api': 1, 'interactions': 1, 'sql': 1, 'advanced': 1, 'r': 1, 'gitgithub': 1, 'interests': 1, 'contributing': 1, 'opensource': 1, 'pandas': 1, 'designing': 1, 'apps': 1, 'cloud': 1, 'aws': 1})\n",
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create a list sorte_words to put the result of the for loop. We sort the word count to get the largest count first. The words are picked from the word_count output. The `[:10]` indicates how many to get and this is taking only the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n",
      "Token: mining               Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
